{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS229, Fall 2017\n",
    "## Problem Set 3: Deep Learning & Unsupervised Learning\n",
    "### 1. A Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "For batch gradient descent used in neural network, the update value is just **the average of the summation of the gradient value of each individual training example!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sigmoid function, we have:\n",
    "\\begin{align*}\n",
    "g(x)'=(\\frac{1}{1+e^{-x}})'=\\frac{e^{-x}}{1+e^{-2x}+2e^{-x}}=\\frac{1}{\\frac{e^{2x}+2e^x+1}{e^x}}=\\frac{e^x}{(1+e^x)^2}=g(x)\\cdot (1-g(x))\n",
    "\\end{align*}\n",
    "In order to update $w_{1,2}^{[1]}$, we need to calculate:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell}{\\partial w_{1,2}^{[1]}}&=\\frac{\\partial \\ell}{\\partial o}\\frac{\\partial o}{\\partial h_2}\\frac{\\partial h_2}{\\partial w_{1,2}^{[1]}}\\\\\n",
    "&=\\frac{2}{m}\\sum_{i=1}^n(o^{(i)}-y^{(i)})o^{(i)}(1-o^{(i)})w_2^{[2]}h_2^{(i)}(1-h_2^{(i)})x_1^{(i)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "From the figure given we know that the training data can be classified by a triangular boundary. To simplify the problem, we may assume that the boundary can be obtained by connecting three points, say $(0.25, 0.25), (0.25, 3.75), (3.75, 0.25)$. Therefore, the three lines is:\n",
    "\\begin{equation*}\n",
    "    \\left\\{\n",
    "    \\begin{matrix}\n",
    "    x_1-0.25=0\\\\\n",
    "    x_2-0.25=0\\\\\n",
    "    x_1+x_2-4=0\\\\\n",
    "    \\end{matrix}\n",
    "    \\right.\n",
    "\\end{equation*}  \n",
    "It is quite obvious from the figure that in order for a sample to be predicted as label 0, it has to satisfy that:\n",
    "\\begin{equation*}\n",
    "    \\left\\{\n",
    "    \\begin{matrix}\n",
    "    x_1-0.25>0\\\\\n",
    "    x_2-0.25>0\\\\\n",
    "    x_1+x_2-4<0\\\\\n",
    "    \\end{matrix}\n",
    "    \\right.\n",
    "\\end{equation*}  \n",
    "We may let the three seperated hidden neurons representing the above three lines respectively and then grouping them together to get the final output. Therefore, the weight can be set as follows:\n",
    "\\begin{align*}\n",
    "&w_{0,1}^{[1]}=0.25, w_{1,1}^{[1]}=-1, w_{2,1}^{[1]}=0\\\\\n",
    "&w_{0,2}^{[1]}=0.25, w_{1,2}^{[1]}=0, w_{2,2}^{[1]}=-1\\\\\n",
    "&w_{0,3}^{[1]}=-4, w_{1,3}^{[1]}=1, w_{2,3}^{[1]}=1\\\\\n",
    "&w_0^{[2]}=-1, w_1^{[2]}=1, w_2^{[2]}=1, w_3^{[2]}=1\\\\\n",
    "\\end{align*}  \n",
    "Because we use step function as the activation function, it is easy to verify that the output of this neural network is 0 (we predict it label 0) if and only if the output of the three hidden neurons are all zeros, which means that the above three ineuqations hold (which also means it has label 0), and for all the other cases (when data has label 1), the output of our network will also be 1. Therefore, 100% accuracy achieved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "There does not exist any specific set of weights that can make the loss 0.  \n",
    "Proof: Because the activation function for the hidden layer is an identity (linear) function, the output can be expressed as:\n",
    "$$o=f(W^{\\mathrm T}X+b)$$\n",
    "where $f$ is the step function.  \n",
    "Therefore, for any given data point $X_0$ to be predicted as label 0, we have:\n",
    "$$W^{\\mathrm T}X_0+b<0$$\n",
    "which apparently is not a triangular area. Therefore, there must exist points that have wrong predictions and the loss can't be 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
