{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS229, Fall 2017\n",
    "\n",
    "## Problem Set 1: Supervised Learning\n",
    "### 2. Poisson regression and the exponential family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression and linear regression both belong to the a more wider class of model called **'Generalized Linear Model' (GLM)**. Models belong to this class have the following assumptions:\n",
    "1. Given $x$ and $\\theta$, the distribution of $y|x;\\sim EF(\\eta)$, where $EF(\\eta)$ stands for exponential family distribution with parameter $\\eta$.\n",
    "2. Given $x$, our model has to output the value of $E(T(y)|x)$, where usually $T(y)=y$.\n",
    "3. The natural parameter $\\eta$ and the inputs $x$ are related linearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "We can write $p(y;\\lambda)$ as:\n",
    "\\begin{align*}\n",
    "p(y;\\lambda)\n",
    "&=\\frac{e^{-\\lambda}\\lambda^y}{y!}\\\\\n",
    "&=\\frac{1}{y!}e^{-\\lambda}e^{y\\ln\\lambda}\\\\\n",
    "&=\\frac{1}{y!}e^{(y\\ln\\lambda)-\\lambda}\\\\\n",
    "\\end{align*}\n",
    "So we have:\n",
    "\\begin{align*}\n",
    "b(y)=\\frac{1}{y!}\\\\\n",
    "\\eta=\\ln\\lambda\\\\\n",
    "T(y)=y\\\\\n",
    "a(\\eta)=e^\\eta\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "According to the assmuption 2. above and because the response variable $y$ obeys Poisson distribution, we know the canonical response function should be:\n",
    "\\begin{align*}\n",
    "h_{\\theta}(x)\n",
    "&=E[y|x;\\theta]\\\\\n",
    "&=\\lambda\\\\\n",
    "&=e^\\eta\\\\\n",
    "&=e^{\\theta^{\\mathrm T}x}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "We can write $p(y^{(i)}|x^{(i)};\\theta)$ as:\n",
    "\\begin{align*}\n",
    "p(y^{(i)}|x^{(i)};\\theta)\n",
    "&=\\frac{1}{y^{(i)}!}e^{(y^{(i)}\\ln\\lambda)-\\lambda}\\\\\n",
    "&=\\frac{1}{y^{(i)}!}e^{(y^{(i)}\\ln e^{\\theta^{\\mathrm T}x^{(i)}})-e^{\\theta^{\\mathrm T}x^{(i)}}}\n",
    "\\end{align*}\n",
    "So, the log likelihood of one sample is:\n",
    "\\begin{align*}\n",
    "\\log p(y^{(i)}|x^{(i)};\\theta)\n",
    "&=\\log \\bigg(\\frac{1}{y^{(i)}!}e^{(y^{(i)}\\ln e^{\\theta^{\\mathrm T}x^{(i)}})-e^{\\theta^{\\mathrm T}x^{(i)}}}\\bigg)\n",
    "\\end{align*}\n",
    "By taking the derivative of $\\log p(y^{(i)}|x^{(i)};\\theta)$ with respect to $\\theta_j$, we have:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\log p(y^{(i)}|x^{(i)};\\theta)}{\\partial \\theta_j}\n",
    "&=\\frac{1}{\\frac{1}{y^{(i)}!}e^{(y^{(i)}\\ln e^{\\theta^{\\mathrm T}x^{(i)}})-e^{\\theta^{\\mathrm T}x^{(i)}}}}\\bigg(\\frac{1}{y^{(i)}!}e^{(y^{(i)}\\ln e^{\\theta^{\\mathrm T}x^{(i)}})-e^{\\theta^{\\mathrm T}x^{(i)}}}(y^{(i)}-e^{\\theta^{\\mathrm T}x^{(i)}})x^{(i)}_j\\bigg)\\\\\n",
    "&=(y^{(i)}-e^{\\theta^{\\mathrm T}x^{(i)}})x^{(i)}_j\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "Maybe I will finish this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
